## Brief van de projectleiders

De OWASP Top 10 voor Large Language Model Applications begon in 2023 als een door de gemeenschap aangestuurde inspanning om beveiligingsproblemen die specifiek zijn voor AI-toepassingen onder de aandacht te brengen en aan te pakken. Sindsdien is de technologie zich blijven verspreiden over sectoren en toepassingen, en dat geldt ook voor de daaraan verbonden risico's. Nu LLM's dieper zijn ingebed in alles, van klantinteracties tot interne activiteiten, ontdekken ontwikkelaars en beveiligingsprofessionals nieuwe kwetsbaarheden - en manieren om deze tegen te gaan.

De lijst van 2023 was een groot succes bij het vergroten van het bewustzijn en het leggen van een basis voor veilig LLM-gebruik, maar sindsdien hebben we nog meer geleerd. In deze nieuwe versie van 2025 hebben we samengewerkt met een grotere, meer diverse groep bijdragers over de hele wereld die allemaal hebben bijgedragen aan het vormgeven van deze lijst. Het proces omvatte brainstormsessies, stemmen en feedback uit de praktijk van professionals die zich bezighielden met de beveiliging van LLM-applicaties, door deze inzendingen bij te dragen of te verfijnen door middel van feedback. Elke stem was van cruciaal belang om deze nieuwe release zo grondig en praktisch mogelijk te maken.

### Wat is er nieuw in de Top 10 van 2025

De lijst voor 2025 weerspiegelt een beter begrip van de bestaande risico's en introduceert cruciale updates over de manier waarop LLM's tegenwoordig in echte toepassingen worden gebruikt. **Unbounded Consumption** breidt bijvoorbeeld uit op wat voorheen Denial of Service was en omvat risico's rond resourcebeheer en onverwachte kosten: een urgent probleem bij grootschalige LLM-implementaties.

Het item **Vector en Embeddings** beantwoordt aan de verzoeken van de community om begeleiding bij het beveiligen van Retrieval-Augmented Generation (RAG) en andere op insluitingen gebaseerde methoden, die nu kernpraktijken zijn voor het aarden van modeluitvoer.

We hebben ook **Systeempromptlekkage** toegevoegd om een ​​probleem aan te pakken met echte exploits waar de community veel om vroeg. Veel applicaties gingen ervan uit dat prompts veilig geïsoleerd waren, maar recente incidenten hebben aangetoond dat ontwikkelaars er niet veilig van kunnen uitgaan dat de informatie in deze prompts geheim blijft.

**Excessive Agency** is uitgebreid, gezien het toegenomen gebruik van agentische architecturen die de LLM meer autonomie kunnen geven.  Omdat LLM's optreden als agenten of in plug-in-instellingen, kunnen niet-gecontroleerde machtigingen leiden tot onbedoelde of risicovolle acties, waardoor deze invoer belangrijker dan ooit wordt.

### Vooruit

Net als de technologie zelf is deze lijst een product van de inzichten en ervaringen van de open-sourcegemeenschap. Het is vormgegeven door bijdragen van ontwikkelaars, datawetenschappers en beveiligingsexperts uit verschillende sectoren, die zich allemaal inzetten voor het bouwen van veiligere AI-toepassingen. We zijn er trots op om deze 2025-versie met u te delen, en we hopen dat deze u de tools en kennis biedt om LLM's effectief te beveiligen.

Dank aan iedereen die heeft geholpen dit samen te brengen en aan degenen die het blijven gebruiken en verbeteren. We zijn dankbaar dat we samen met u deel kunnen uitmaken van dit werk.


###@ Steve Wilson
Project Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/wilsonsd/

###@ Ads Dawson
Technical Lead & Vulnerability Entries Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/adamdawson0/
