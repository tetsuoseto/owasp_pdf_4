## Brev fra prosjektlederne

OWASP Topp 10 for store språkmodellapplikasjoner startet i 2023 som en fellesskapsdrevet innsats for å fremheve og adressere sikkerhetsproblemer som er spesifikke for AI-applikasjoner. Siden den gang har teknologien fortsatt å spre seg på tvers av bransjer og applikasjoner, og det samme har de tilhørende risikoene. Ettersom LLM-er er dypere innebygd i alt fra kundeinteraksjoner til interne operasjoner, oppdager utviklere og sikkerhetseksperter nye sårbarheter – og måter å motvirke dem på.

2023-listen var en stor suksess med å øke bevisstheten og bygge et grunnlag for sikker LLM-bruk, men vi har lært enda mer siden den gang. I denne nye 2025-versjonen har vi jobbet med en større, mer mangfoldig gruppe av bidragsytere over hele verden som alle har vært med på å forme denne listen. Prosessen innebar idédugnad, stemmegivning og tilbakemeldinger fra den virkelige verden fra fagfolk innen LLM-applikasjonssikkerhet, enten ved å bidra med eller avgrense disse oppføringene gjennom tilbakemelding. Hver stemme var avgjørende for å gjøre denne nye utgivelsen så grundig og praktisk som mulig.

### Hva er nytt i 2025 Topp 10

2025-listen gjenspeiler en bedre forståelse av eksisterende risikoer og introduserer kritiske oppdateringer om hvordan LLM-er brukes i virkelige applikasjoner i dag. **Ubundet forbruk** utvider for eksempel det som tidligere var tjenestenekt til å inkludere risikoer rundt ressursstyring og uventede kostnader – et presserende problem i storskala LLM-implementeringer.

**Vector and Embeddings**-oppføringen svarer på fellesskapets forespørsler om veiledning for å sikre Retrieval-Augmented Generation (RAG) og andre innbyggingsbaserte metoder, nå kjernepraksis for jording av modellutganger.

Vi har også lagt til **System Prompt Leakage** for å adressere et område med virkelige utnyttelser som var sterkt etterspurt av fellesskapet. Mange applikasjoner antok at forespørsler var sikkert isolert, men nylige hendelser har vist at utviklere ikke trygt kan anta at informasjonen i disse ledetekstene forblir hemmelig.

**Excessive Agency** har blitt utvidet, gitt økt bruk av agentarkitekturer som kan gi LLM mer autonomi.  Med LLM-er som fungerer som agenter eller i plugin-innstillinger, kan ukontrollerte tillatelser føre til utilsiktede eller risikable handlinger, noe som gjør denne oppføringen mer kritisk enn noen gang.

### Går fremover

I likhet med teknologien i seg selv, er denne listen et produkt av åpen kildekode-fellesskapets innsikt og erfaringer. Den har blitt formet av bidrag fra utviklere, dataforskere og sikkerhetseksperter på tvers av sektorer, alle forpliktet til å bygge sikrere AI-applikasjoner. Vi er stolte av å dele denne 2025-versjonen med deg, og vi håper den gir deg verktøy og kunnskap for å sikre LLM-er effektivt.

Takk til alle som bidro til å bringe dette sammen og de som fortsetter å bruke og forbedre det. Vi er takknemlige for å være en del av dette arbeidet med deg.


###@ Steve Wilson
Project Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/wilsonsd/

###@ Ads Dawson
Technical Lead & Vulnerability Entries Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/adamdawson0/
