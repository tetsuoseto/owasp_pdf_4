## Carta dos líderes do projeto

O OWASP Top 10 para Aplicações de Modelos de Linguagem Grande começou em 2023 como um esforço conduzido pela comunidade para destacar e resolver problemas de segurança específicos para aplicações de IA. Desde então, a tecnologia continuou a espalhar-se pelas indústrias e aplicações, tal como os riscos associados. À medida que os LLM são incorporados mais profundamente em tudo, desde as interações com os clientes às operações internas, os programadores e os profissionais de segurança estão a descobrir novas vulnerabilidades — e formas de as combater.

A lista de 2023 foi um grande sucesso na sensibilização e na construção de uma base para a utilização segura do LLM, mas aprendemos ainda mais desde então. Nesta nova versão de 2025, trabalhámos com um grupo maior e mais diversificado de colaboradores em todo o mundo que ajudaram a moldar esta lista. O processo envolveu sessões de brainstorming, votação e feedback do mundo real de profissionais da área de segurança de aplicações LLM, quer contribuindo ou refinando estas entradas através de feedback. Cada voz foi fundamental para tornar este novo lançamento o mais completo e prático possível.

### O que há de novo no Top 10 de 2025

A lista de 2025 reflete uma melhor compreensão dos riscos existentes e introduz atualizações críticas sobre a forma como os LLM são atualmente utilizados em aplicações do mundo real. Por exemplo, **Consumo ilimitado** expande o que anteriormente era negação de serviço para incluir riscos relacionados com a gestão de recursos e custos inesperados – uma questão urgente em implementações de LLM em grande escala.

A entrada **Vetores e Embeddings** responde aos pedidos da comunidade de orientação sobre como proteger a Geração Aumentada de Recuperação (RAG) e outros métodos baseados na incorporação, agora práticas essenciais para fundamentar os resultados do modelo.

Também adicionámos **System Prompt Leakage** para abordar uma área com explorações do mundo real que foram altamente solicitadas pela comunidade. Muitas aplicações assumiram que os avisos foram isolados com segurança, mas incidentes recentes mostraram que os programadores não podem assumir com segurança que as informações nesses avisos permanecem secretas.

**Agência Excessiva** foi alargada, dado o aumento da utilização de arquiteturas de agência que podem dar mais autonomia ao LLM.  Com os LLMs a atuar como agentes ou em configurações de plug-ins, as permissões não verificadas podem levar a ações não intencionais ou arriscadas, tornando esta entrada mais crítica do que nunca.

### Seguindo em frente

Tal como a própria tecnologia, esta lista é um produto dos conhecimentos e experiências da comunidade de código aberto. Foi moldado por contribuições de programadores, cientistas de dados e especialistas em segurança de todos os setores, todos empenhados na construção de aplicações de IA mais seguras. Temos orgulho em partilhar esta versão 2025 consigo e esperamos que forneça as ferramentas e o conhecimento para proteger os LLMs de forma eficaz.

Obrigado a todos os que ajudaram a unir isto e a todos os que continuam a usá-lo e a melhorá-lo. Estamos gratos por fazer parte deste trabalho consigo.


###@ Steve Wilson
Project Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/wilsonsd/

###@ Ads Dawson
Technical Lead & Vulnerability Entries Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/adamdawson0/
