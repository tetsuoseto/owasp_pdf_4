## Carta de los líderes del proyecto

El OWASP Top 10 para aplicaciones de modelos de lenguajes grandes comenzó en 2023 como un esfuerzo impulsado por la comunidad para resaltar y abordar problemas de seguridad específicos de las aplicaciones de IA. Desde entonces, la tecnología ha seguido extendiéndose entre industrias y aplicaciones, al igual que los riesgos asociados. A medida que los LLM se integran más profundamente en todo, desde las interacciones con los clientes hasta las operaciones internas, los desarrolladores y profesionales de la seguridad están descubriendo nuevas vulnerabilidades y formas de contrarrestarlas.

La lista de 2023 fue un gran éxito a la hora de crear conciencia y sentar las bases para el uso seguro del LLM, pero hemos aprendido aún más desde entonces. En esta nueva versión 2025, hemos trabajado con un grupo más grande y diverso de contribuyentes en todo el mundo que han ayudado a dar forma a esta lista. El proceso implicó sesiones de lluvia de ideas, votaciones y comentarios del mundo real de profesionales involucrados en la seguridad de las aplicaciones LLM, ya sea contribuyendo o refinando esas entradas a través de comentarios. Cada voz fue fundamental para que esta nueva versión fuera lo más completa y práctica posible.

### Novedades del Top 10 de 2025

La lista de 2025 refleja una mejor comprensión de los riesgos existentes e introduce actualizaciones críticas sobre cómo se utilizan los LLM en aplicaciones del mundo real en la actualidad. Por ejemplo, **Consumo ilimitado** amplía lo que anteriormente era Denegación de servicio para incluir riesgos relacionados con la gestión de recursos y costos inesperados, un problema apremiante en implementaciones de LLM a gran escala.

La entrada **Vectores e incrustaciones** responde a las solicitudes de orientación de la comunidad sobre cómo asegurar la generación aumentada de recuperación (RAG) y otros métodos basados ​​en la incrustación, que ahora son prácticas centrales para conectar a tierra los resultados del modelo.

También agregamos **Fuga de aviso del sistema** para abordar un área con vulnerabilidades del mundo real que fueron muy solicitadas por la comunidad. Muchas aplicaciones asumieron que los mensajes estaban aislados de forma segura, pero incidentes recientes han demostrado que los desarrolladores no pueden asumir con seguridad que la información de estos mensajes permanece secreta.

**Agencia excesiva** se ha ampliado, dado el mayor uso de arquitecturas de agencia que pueden darle al LLM más autonomía.  Cuando los LLM actúan como agentes o en configuraciones de complementos, los permisos no controlados pueden dar lugar a acciones no deseadas o riesgosas, lo que hace que esta entrada sea más crítica que nunca.

### Avanzando

Al igual que la tecnología misma, esta lista es producto de los conocimientos y experiencias de la comunidad de código abierto. Ha sido moldeado por contribuciones de desarrolladores, científicos de datos y expertos en seguridad de todos los sectores, todos comprometidos con la creación de aplicaciones de IA más seguras. Estamos orgullosos de compartir con usted esta versión 2025 y esperamos que le brinde las herramientas y el conocimiento para asegurar sus LLM de manera efectiva.

Gracias a todos los que ayudaron a crear esto y a aquellos que continúan usándolo y mejorándolo. Estamos agradecidos de ser parte de este trabajo con usted.


###@ Steve Wilson
Project Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/wilsonsd/

###@ Ads Dawson
Technical Lead & Vulnerability Entries Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/adamdawson0/
