## Brief der Projektleiter

Die OWASP Top 10 für große Sprachmodellanwendungen wurden 2023 als eine von der Community getragene Initiative ins Leben gerufen, um Sicherheitsprobleme, die für KI-Anwendungen spezifisch sind, hervorzuheben und anzugehen. Seitdem hat sich die Technologie immer weiter über Branchen und Anwendungen verbreitet, und damit auch die damit verbundenen Risiken. Da LLMs immer tiefer in alles eingebettet sind, von Kundeninteraktionen bis hin zu internen Abläufen, entdecken Entwickler und Sicherheitsexperten neue Schwachstellen – und Möglichkeiten, ihnen entgegenzuwirken.

Die Liste 2023 war ein großer Erfolg bei der Sensibilisierung und dem Aufbau einer Grundlage für eine sichere LLM-Nutzung, aber wir haben seitdem noch mehr gelernt. In dieser neuen Version für 2025 haben wir mit einer größeren, vielfältigeren Gruppe von Mitwirkenden weltweit zusammengearbeitet, die alle bei der Erstellung dieser Liste mitgewirkt haben. Der Prozess umfasste Brainstorming-Sitzungen, Abstimmungen und reales Feedback von Fachleuten aus der LLM-Anwendungssicherheit, sei es durch Beiträge oder die Verfeinerung dieser Einträge durch Feedback. Jede Stimme war entscheidend dafür, diese neue Veröffentlichung so gründlich und praktisch wie möglich zu gestalten.

### Was ist neu in den Top 10 2025?

Die Liste 2025 spiegelt ein besseres Verständnis bestehender Risiken wider und führt wichtige Aktualisierungen darüber ein, wie LLMs heute in realen Anwendungen eingesetzt werden. Beispielsweise erweitert **Unbounded Consumption** das, was zuvor Denial of Service bedeutete, um Risiken im Zusammenhang mit der Ressourcenverwaltung und unerwarteten Kosten – ein dringendes Problem bei groß angelegten LLM-Bereitstellungen.

Der Eintrag **Vector and Embeddings** reagiert auf die Anfragen der Community nach Anleitung zur Sicherung der Retrieval-Augmented Generation (RAG) und anderer einbettungsbasierter Methoden, die heute Kernpraktiken für die Erdung von Modellausgaben sind.

Wir haben außerdem **System Prompt Leakage** hinzugefügt, um einen Bereich mit realen Exploits zu beheben, die von der Community stark nachgefragt wurden. Viele Anwendungen gingen davon aus, dass Eingabeaufforderungen sicher isoliert seien, doch jüngste Vorfälle haben gezeigt, dass Entwickler nicht mit Sicherheit davon ausgehen können, dass die Informationen in diesen Eingabeaufforderungen geheim bleiben.

**Excessive Agency** wurde erweitert, da zunehmend Agentenarchitekturen eingesetzt werden, die dem LLM mehr Autonomie verleihen können.  Da LLMs als Agenten oder in Plug-in-Einstellungen fungieren, können ungeprüfte Berechtigungen zu unbeabsichtigten oder riskanten Aktionen führen, was diesen Eintrag wichtiger denn je macht.

### Vorwärts gehen

Wie die Technologie selbst ist diese Liste ein Produkt der Erkenntnisse und Erfahrungen der Open-Source-Community. Es wurde durch Beiträge von Entwicklern, Datenwissenschaftlern und Sicherheitsexperten aus verschiedenen Sektoren geprägt, die sich alle für die Entwicklung sichererer KI-Anwendungen einsetzen. Wir sind stolz darauf, diese Version 2025 mit Ihnen zu teilen, und wir hoffen, dass sie Ihnen die Tools und das Wissen an die Hand gibt, um LLMs effektiv zu sichern.

Vielen Dank an alle, die dabei geholfen haben, dies zusammenzustellen, und an diejenigen, die es weiterhin nutzen und verbessern. Wir sind dankbar, mit Ihnen Teil dieser Arbeit zu sein.

###@ Steve Wilson
Project Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/wilsonsd/

###@ Ads Dawson
Technical Lead & Vulnerability Entries Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/adamdawson0/
