## Lettera dei responsabili del progetto

La Top 10 OWASP per applicazioni di modelli linguistici di grandi dimensioni è iniziata nel 2023 come sforzo guidato dalla comunità per evidenziare e affrontare i problemi di sicurezza specifici delle applicazioni IA. Da allora, la tecnologia ha continuato a diffondersi in tutti i settori e nelle applicazioni, così come i rischi associati. Poiché gli LLM sono integrati sempre più profondamente in ogni aspetto, dalle interazioni con i clienti alle operazioni interne, gli sviluppatori e i professionisti della sicurezza stanno scoprendo nuove vulnerabilità e modi per contrastarle.

L'elenco del 2023 è stato un grande successo nel sensibilizzare l'opinione pubblica e nel costruire le basi per un utilizzo sicuro del LLM, ma da allora abbiamo imparato ancora di più. In questa nuova versione del 2025, abbiamo lavorato con un gruppo più ampio e diversificato di contributori in tutto il mondo che hanno tutti contribuito a dare forma a questo elenco. Il processo prevedeva sessioni di brainstorming, votazioni e feedback dal mondo reale da parte di professionisti nel pieno della sicurezza delle applicazioni LLM, contribuendo o perfezionando tali voci tramite feedback. Ogni voce è stata fondamentale per rendere questa nuova versione quanto più completa e pratica possibile.

### Novità nella Top 10 del 2025

L'elenco del 2025 riflette una migliore comprensione dei rischi esistenti e introduce aggiornamenti critici su come gli LLM vengono utilizzati oggi nelle applicazioni del mondo reale. Ad esempio, **Unbounded Consumption** espande ciò che in precedenza era Denial of Service per includere rischi legati alla gestione delle risorse e costi imprevisti, un problema urgente nelle implementazioni LLM su larga scala.

La voce **Vettore e incorporamenti** risponde alle richieste della comunità di indicazioni sulla protezione della generazione aumentata di recupero (RAG) e altri metodi basati sull'incorporamento, ora pratiche fondamentali per radicare gli output del modello.

Abbiamo anche aggiunto **System Prompt Leakage** per affrontare un'area con exploit del mondo reale molto richiesti dalla community. Molte applicazioni presuppongono che i prompt fossero isolati in modo sicuro, ma recenti incidenti hanno dimostrato che gli sviluppatori non possono presumere con sicurezza che le informazioni contenute in questi prompt rimangano segrete.

**Agenzia eccessiva** è stata ampliata, dato il maggiore utilizzo di architetture ad agenti che possono dare maggiore autonomia al LLM.  Con gli LLM che agiscono come agenti o nelle impostazioni dei plug-in, le autorizzazioni non controllate possono portare ad azioni indesiderate o rischiose, rendendo questa voce più critica che mai.

### Andare avanti

Come la tecnologia stessa, questo elenco è il prodotto delle intuizioni e delle esperienze della comunità open source. È stato plasmato dai contributi di sviluppatori, data scientist ed esperti di sicurezza di tutti i settori, tutti impegnati a creare applicazioni IA più sicure. Siamo orgogliosi di condividere con te questa versione 2025 e speriamo che ti fornisca gli strumenti e le conoscenze per proteggere efficacemente i LLM.

Grazie a tutti coloro che hanno contribuito a realizzarlo e a coloro che continuano a utilizzarlo e migliorarlo. Siamo grati di far parte di questo lavoro con te.


###@ Steve Wilson
Project Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/wilsonsd/

###@ Ads Dawson
Technical Lead & Vulnerability Entries Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/adamdawson0/
