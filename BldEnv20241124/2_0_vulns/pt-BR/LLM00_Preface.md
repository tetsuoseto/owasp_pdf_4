## Carta dos líderes do projeto

O OWASP Top 10 para Aplicações de Modelos de Linguagem Grande começou em 2023 como um esforço conduzido pela comunidade para destacar e resolver problemas de segurança específicos para aplicações de IA. Desde então, a tecnologia continuou a espalhar-se pelas indústrias e aplicações, tal como os riscos associados. À medida que os LLMs são incorporados mais profundamente em tudo, desde interações com clientes até operações internas, os desenvolvedores e profissionais de segurança estão descobrindo novas vulnerabilidades — e maneiras de combatê-las.

A lista de 2023 foi um grande sucesso na conscientização e na construção de uma base para o uso seguro do LLM, mas aprendemos ainda mais desde então. Nesta nova versão de 2025, trabalhamos com um grupo maior e mais diversificado de colaboradores em todo o mundo que ajudaram a moldar esta lista. O processo envolveu sessões de brainstorming, votação e feedback do mundo real de profissionais da área de segurança de aplicativos LLM, seja contribuindo ou refinando essas entradas por meio de feedback. Cada voz foi fundamental para tornar este novo lançamento o mais completo e prático possível.

### O que há de novo no Top 10 de 2025

A lista de 2025 reflete uma melhor compreensão dos riscos existentes e introduz atualizações críticas sobre como os LLMs são usados ​​atualmente em aplicações do mundo real. Por exemplo, **Consumo ilimitado** expande o que anteriormente era negação de serviço para incluir riscos relacionados ao gerenciamento de recursos e custos inesperados – uma questão urgente em implantações de LLM em grande escala.

A entrada **Vetores e Embeddings** responde às solicitações da comunidade de orientação sobre como proteger a Geração Aumentada de Recuperação (RAG) e outros métodos baseados em incorporação, agora práticas essenciais para fundamentar os resultados do modelo.

Também adicionamos **System Prompt Leakage** para abordar uma área com explorações do mundo real que foram altamente solicitadas pela comunidade. Muitos aplicativos assumiram que os prompts foram isolados com segurança, mas incidentes recentes mostraram que os desenvolvedores não podem assumir com segurança que as informações nesses prompts permanecem secretas.

**Agência Excessiva** foi ampliada, dado o aumento do uso de arquiteturas de agência que podem dar mais autonomia ao LLM.  Com os LLMs atuando como agentes ou em configurações de plug-ins, permissões não verificadas podem levar a ações não intencionais ou arriscadas, tornando essa entrada mais crítica do que nunca.

### Seguindo em frente

Tal como a própria tecnologia, esta lista é um produto dos conhecimentos e experiências da comunidade de código aberto. Foi moldado por contribuições de desenvolvedores, cientistas de dados e especialistas em segurança de todos os setores, todos comprometidos com a construção de aplicações de IA mais seguras. Temos orgulho de compartilhar esta versão 2025 com você e esperamos que ela forneça as ferramentas e o conhecimento para proteger LLMs de maneira eficaz.

Obrigado a todos que ajudaram a unir isso e a todos que continuam a usá-lo e melhorá-lo. Somos gratos por fazer parte deste trabalho com você.


###@ Steve Wilson
Project Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/wilsonsd/

###@ Ads Dawson
Technical Lead & Vulnerability Entries Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/adamdawson0/
