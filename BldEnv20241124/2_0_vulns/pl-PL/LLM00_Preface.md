## List od Liderów Projektu

Lista 10 najlepszych rozwiązań OWASP w zakresie aplikacji modeli wielkojęzykowych powstała w 2023 r. jako inicjatywa społeczności mająca na celu podkreślenie i rozwiązanie problemów związanych z bezpieczeństwem specyficznych dla aplikacji AI. Od tego czasu technologia ta nadal rozprzestrzenia się w różnych branżach i zastosowaniach, a wraz z nią związane z nią ryzyko. Ponieważ LLM są głębiej osadzone we wszystkim, od interakcji z klientami po operacje wewnętrzne, programiści i specjaliści ds. bezpieczeństwa odkrywają nowe luki w zabezpieczeniach i sposoby im przeciwdziałania.

Lista na rok 2023 odniosła duży sukces w podnoszeniu świadomości i budowaniu podstaw bezpiecznego korzystania z LLM, ale od tego czasu nauczyliśmy się jeszcze więcej. W nowej wersji na rok 2025 współpracowaliśmy z większą, bardziej zróżnicowaną grupą autorów z całego świata, którzy pomogli w ukształtowaniu tej listy. Proces obejmował sesje burzy mózgów, głosowanie i opinie ze świata rzeczywistego od profesjonalistów zajmujących się bezpieczeństwem aplikacji LLM, czy to poprzez wnoszenie wkładu, czy udoskonalanie tych wpisów w drodze opinii. Każdy głos miał kluczowe znaczenie, aby nowe wydanie było jak najbardziej dokładne i praktyczne.

### Co nowego w Top 10 2025

Lista na rok 2025 odzwierciedla lepsze zrozumienie istniejących zagrożeń i wprowadza krytyczne aktualizacje dotyczące dzisiejszego wykorzystania LLM w rzeczywistych zastosowaniach. Na przykład **Nieograniczona konsumpcja** rozszerza to, co wcześniej było odmową usługi, obejmując ryzyko związane z zarządzaniem zasobami i nieoczekiwanymi kosztami – palący problem we wdrożeniach LLM na dużą skalę.

Wpis **Wektor i osadzanie** odpowiada na prośby społeczności o wytyczne dotyczące zabezpieczania generacji wspomaganej pobieraniem (RAG) i innych metod opartych na osadzaniu, które są obecnie podstawowymi praktykami w przypadku wyników modelu uziemienia.

Dodaliśmy także **Wyciek komunikatu systemowego**, aby zająć się obszarem, w którym występują exploity w świecie rzeczywistym, bardzo pożądane przez społeczność. Wiele aplikacji zakładało, że monity zostały bezpiecznie odizolowane, ale ostatnie incydenty pokazały, że programiści nie mogą bezpiecznie zakładać, że informacje zawarte w tych monitach pozostaną tajne.

**Nadmierna agencja** została rozszerzona, biorąc pod uwagę zwiększone wykorzystanie architektur agentycznych, które mogą zapewnić LLM większą autonomię.  W przypadku LLM działających jako agenci lub w ustawieniach wtyczek niesprawdzone uprawnienia mogą prowadzić do niezamierzonych lub ryzykownych działań, przez co ten wpis staje się bardziej krytyczny niż kiedykolwiek.

### Idąc dalej

Podobnie jak sama technologia, ta lista jest wynikiem spostrzeżeń i doświadczeń społeczności open source. Został on ukształtowany dzięki wkładowi programistów, analityków danych i ekspertów ds. bezpieczeństwa z różnych sektorów, a wszyscy zaangażowani są w tworzenie bezpieczniejszych aplikacji AI. Z dumą udostępniamy Ci wersję 2025 i mamy nadzieję, że zapewni ona narzędzia i wiedzę umożliwiające skuteczne zabezpieczanie LLM.

Dziękuję wszystkim, którzy pomogli w stworzeniu tego razem, oraz tym, którzy nadal z niego korzystają i ulepszają. Jesteśmy wdzięczni, że możemy być częścią tej pracy razem z Tobą.


###@ Steve Wilson
Project Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/wilsonsd/

###@ Ads Dawson
Technical Lead & Vulnerability Entries Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/adamdawson0/
