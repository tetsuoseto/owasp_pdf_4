## Projekto vadovų laiškas

OWASP 10 geriausių didelių kalbų modelių taikomųjų programų startavo 2023 m. kaip bendruomenės pastangos pabrėžti ir spręsti su dirbtinio intelekto programomis susijusias saugumo problemas. Nuo tada technologija ir toliau plito įvairiose pramonės šakose ir taikomosiose srityse, taip pat ir su tuo susijusi rizika. Kadangi LLM yra labiau įtrauktos į viską, pradedant sąveika su klientais ir baigiant vidaus operacijomis, kūrėjai ir saugos specialistai atranda naujų pažeidžiamumų ir būdų, kaip su jomis kovoti.

2023 m. sąrašas buvo labai sėkmingas didinant informuotumą ir sukuriant pagrindą saugiam LLM naudojimui, tačiau nuo to laiko išmokome dar daugiau. Šioje naujoje 2025 m. versijoje dirbome su didesne ir įvairesne bendraautorių grupe visame pasaulyje, kurie padėjo sudaryti šį sąrašą. Procesas apėmė minčių šturmą, balsavimą ir realius atsiliepimus iš profesionalų, besidominčių LLM programų saugumu, tiek prisidedant, tiek patobulinant tuos įrašus per grįžtamąjį ryšį. Kiekvienas balsas buvo labai svarbus, kad šis naujas leidimas būtų kuo išsamesnis ir praktiškesnis.

### Kas naujo 2025 m. Top 10

2025 m. sąrašas atspindi geresnį esamos rizikos supratimą ir pateikia svarbių atnaujinimų apie tai, kaip LLM šiandien naudojamos realiame pasaulyje. Pavyzdžiui, **Neribotas suvartojimas** praplečia tai, kas anksčiau buvo atsisakyta teikti paslaugą, įtraukdama riziką, susijusią su išteklių valdymu ir netikėtomis išlaidomis – neatidėliotina problema diegiant didelio masto LLM.

Įrašas **Vektoriai ir įterpimai** atsako į bendruomenės prašymus pateikti rekomendacijų, kaip užtikrinti atkūrimo papildytą generavimą (RAG) ir kitus įterpimu pagrįstus metodus, kurie dabar yra pagrindinė modelio išvesties įžeminimo praktika.

Taip pat įtraukėme **System Prompt Leakage**, kad išspręstume sritį su realiais išnaudojimais, kurių labai prašė bendruomenė. Daugelis programų mano, kad raginimai buvo saugiai izoliuoti, tačiau naujausi incidentai parodė, kad kūrėjai negali saugiai manyti, kad informacija šiuose raginimuose lieka slapta.

**Pernelyg didelė agentūra** buvo išplėsta, nes vis dažniau naudojama agentų architektūra, kuri gali suteikti LLM daugiau savarankiškumo.  Kai LLM veikia kaip agentai arba papildinio nustatymuose, nepažymėti leidimai gali sukelti nenumatytų arba rizikingų veiksmų, todėl šis įrašas tampa svarbesnis nei bet kada anksčiau.

### Judėjimas į priekį

Kaip ir pati technologija, šis sąrašas yra atvirojo kodo bendruomenės įžvalgų ir patirties produktas. Jį suformavo kūrėjai, duomenų mokslininkai ir saugos ekspertai iš įvairių sektorių, įsipareigoję kurti saugesnes AI programas. Didžiuojamės galėdami pasidalinti su jumis šia 2025 m. versija ir tikimės, kad ji suteiks jums įrankių ir žinių, kaip veiksmingai apsaugoti LLM.

Dėkojame visiems, padėjusiems tai suburti, ir tiems, kurie toliau naudojasi ir tobulina. Esame dėkingi, kad esame šio darbo dalis kartu su jumis.


###@ Steve Wilson
Project Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/wilsonsd/

###@ Ads Dawson
Technical Lead & Vulnerability Entries Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/adamdawson0/
