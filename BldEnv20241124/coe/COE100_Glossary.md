## Glossary

### AI (Artificial Intelligence)
  The simulation of human intelligence processes by machines, especially computer systems. In the context of this guide, AI refers to systems that use large language models and generative technologies.
### AI Security
  The practice of protecting AI systems from threats, vulnerabilities, and risks. This includes securing data, algorithms, and the infrastructure supporting AI technologies.
### Center of Excellence (CoE)
  A centralized team or structure within an organization designed to promote best practices, provide leadership, and ensure the successful deployment and management of AI and LLM technologies.
### CISO (Chief Information Security Officer)
  The executive responsible for the organization's information and data security.
### Compliance
  Adhering to legal, regulatory, and organizational policies and standards. In AI, this often involves ensuring that AI systems meet privacy, security, and ethical guidelines.
### Data Science Team
  A group responsible for analyzing data, developing machine learning models, and ensuring the accuracy and integrity of AI systems.
### Ethical AI
  The practice of developing and deploying AI systems in a way that is fair, transparent, and aligned with societal values.
### Generative AI
  A type of AI that can create new content, such as text, images, or music, based on training data. Examples include large language models like GPT.
### Governance
  The framework of rules, practices, and processes by which an organization ensures the effective and ethical management of AI technologies.
### Key Performance Indicators (KPIs):
  Metrics used to evaluate the success of an organization, department, or project in achieving its objectives.
### Large Language Models (LLMs)
  A type of AI model designed to understand and generate human language, often trained on vast amounts of text data.
### Machine Learning (ML)
  A subset of AI that involves the use of algorithms and statistical models to enable computers to perform tasks without explicit programming.
### Multidisciplinary Team
  A group composed of members from various departments or fields, such as security, legal, and data science, working together on AI security initiatives.
### Operationalization
  The process of implementing AI systems into an organization's daily operations, including their secure deployment and maintenance.
### Risk Management
  The identification, analysis, and mitigation of risks associated with AI technologies to protect the organization from potential threats.
### Stakeholder Engagement
  The process of involving and communicating with individuals or groups who have an interest in the organizationâ€™s AI initiatives (employees, customers, and regulators).
### Security Framework
  A structured set of guidelines and best practices designed to protect AI systems from threats and ensure their secure deployment.
### Shift-Left Strategy
  A practice that involves incorporating security measures early in the development process, rather than addressing them at the end.
### Trust and Transparency
  Building confidence in AI technologies by ensuring that their operations are understandable, ethical, and aligned with stakeholders' expectations.
### Vulnerability Assessment
  The process of identifying, evaluating, and addressing security weaknesses in AI systems.